{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Train_581.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U8QmrFNVEF6"
      },
      "source": [
        "from Nnet import NNet \n",
        "from MCTS import mcts\n",
        "from Node import Node\n",
        "from Board import Board\n",
        "from config import Config "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrT28AVEYCib"
      },
      "source": [
        "from Game import game"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxzeYwkrXRDs"
      },
      "source": [
        "from AlphaBetaPlayer import AlphaBetaPlayer\n",
        "from BasicPlayer import BasicPlayer\n",
        "from RandomPlayer import RandomPlayer\n",
        "from AlphaZeroPlayer import AlphaZeroPlayer\n",
        "from handPlay import handPlayer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qQPZ-y2KmJf",
        "outputId": "4495bdcb-a89b-407b-a848-6380c68a2f3b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6xwGHxEVEF8"
      },
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import random\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndx5A-xihX-R"
      },
      "source": [
        "import os.path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u5EY-SBzVied",
        "outputId": "a0d3785a-09ec-4641-f2f8-612dceaadefd"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9ObRlz1dVBR"
      },
      "source": [
        "Config.epochs = 10\n",
        "Config.self_games = 20\n",
        "Config.batch_size = 32\n",
        "Config.mcts_iterations = 20\n",
        "Config.verbose = 1\n",
        "Config.callbacks = None\n",
        "Config.eval_games = 15\n",
        "Config.win_threshold = 0.55\n",
        "Config.save_path = '/content/drive/MyDrive/AlphaZeroModels/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhRC1LHFVEF-"
      },
      "source": [
        "class Train():\n",
        "    \n",
        "    def __init__(self, board, model):\n",
        "        self.board = board\n",
        "        self.model = model\n",
        "        self.eval_model = NNet(board.width, board.height)\n",
        "        self.training_states = np.empty((0, board.height, board.width, 2)) \n",
        "        self.training_ps = np.empty((0, board.width))\n",
        "        self.training_vs = np.empty((0))\n",
        "\n",
        "    def start_training(self):\n",
        "\n",
        "        if (os.path.isfile('best_model.h5')): \n",
        "            print('loading best model')\n",
        "            self.model.model = load_model('best_model.h5')\n",
        "\n",
        "        for iteration in range(Config.mcts_iterations):\n",
        "            \n",
        "            print('Iteration :', iteration)\n",
        "\n",
        "            self.training_states = np.empty((0, self.board.height, self.board.width, 2)) \n",
        "            self.training_ps = np.empty((0, self.board.width))\n",
        "            self.training_vs =  np.empty((0))\n",
        "            \n",
        "            # Preparing training data\n",
        "            print('Launching self simulation')\n",
        "            for i in range(Config.self_games):\n",
        "                #print('Simulation self play number :', i)\n",
        "                board = self.board.make_copy()\n",
        "                self.self_play(board)\n",
        "\n",
        "            print('Self simulations done')\n",
        "\n",
        "            self.model.model.save(Config.save_path+'model.h5')\n",
        "\n",
        "            self.eval_model.model = load_model(Config.save_path+'model.h5')\n",
        "\n",
        "            self.model.model.fit(self.training_states,\n",
        "                                 [self.training_ps, self.training_vs],\n",
        "                                 batch_size=Config.batch_size,\n",
        "                                 epochs=Config.epochs,\n",
        "                                 verbose=Config.verbose,\n",
        "                                 callbacks=Config.callbacks)\n",
        "            \n",
        "            current_mcts = mcts(self.model, self.board.width)\n",
        "            eval_mcts = mcts(self.eval_model, self.board.width)\n",
        "\n",
        "            # Play multiple games between the old and the new network\n",
        "            wins, losses = self.evaluate(current_mcts, eval_mcts)\n",
        "            total_games = wins+losses\n",
        "\n",
        "            if total_games == 0:\n",
        "              win_rate = 0\n",
        "            else:\n",
        "              win_rate = wins/total_games\n",
        "\n",
        "            print('Win rate of the new model vs the old model:', win_rate)\n",
        "\n",
        "            if win_rate > Config.win_threshold:\n",
        "              print('New model accepted', end='')\n",
        "              self.model.model.save(Config.save_path+'best_model.h5')\n",
        "              print(' (Saved)')\n",
        "            else:\n",
        "              print('New model rejected ( Deleted )')\n",
        "              if (os.path.isfile(Config.save_path+'best_model.h5')): \n",
        "                self.model.model = load_model(Config.save_path+'best_model.h5')\n",
        "              else:\n",
        "                self.model.model = load_model(Config.save_path+'model.h5')\n",
        "\n",
        "    def self_play(self, board):\n",
        "        \n",
        "        mct = mcts(self.model, self.board.width)\n",
        "        root = Node()\n",
        "        \n",
        "        game_over = False\n",
        "        count = 0\n",
        "        \n",
        "        while not game_over:\n",
        "            \n",
        "            if count < Config.early_training:\n",
        "                best_child = mct.get_move(board, root, temp=Config.initial_temperature)\n",
        "            else:\n",
        "                best_child = mct.get_move(board, root, temp=Config.final_temperature)\n",
        "            \n",
        "            state_iter = board.get_curr_state()\n",
        "            ps_iter = best_child.parent.get_children_ps()\n",
        "            \n",
        "            self.training_states = np.append(self.training_states, state_iter, axis=0)\n",
        "            self.training_ps = np.append(self.training_ps, [ps_iter], axis=0)\n",
        "\n",
        "            board.play_move(best_child.move)\n",
        "\n",
        "            best_child.parent = None\n",
        "            root = best_child\n",
        "            \n",
        "            count += 1\n",
        "            game_over, result = board.game_over()\n",
        "\n",
        "        v_data = np.ones(count)*result            \n",
        "        \n",
        "        self.training_vs = np.append(self.training_vs, v_data, axis=0)\n",
        "\n",
        "    def evaluate(self, mcts1, mcts2):\n",
        "      \n",
        "      wins, losses = 0, 0\n",
        "      print('Start evaluation')\n",
        "      for i in range(Config.eval_games):\n",
        "          #print('Evaluation number:', i)\n",
        "\n",
        "          board = Board()\n",
        "          root = Node()\n",
        "\n",
        "          while not board.game_over()[0]:\n",
        "            \n",
        "            if board.current_player == 1:\n",
        "              child = mcts1.get_move(board, root, temp=Config.final_temperature)\n",
        "            else:\n",
        "              child = mcts2.get_move(board, root, temp=Config.final_temperature)\n",
        "\n",
        "            move = child.move\n",
        "            board.play_move(move)\n",
        "            game_over, result = board.game_over()\n",
        "\n",
        "            child.parent = None\n",
        "            root = child\n",
        "            root.parent = None\n",
        "          board.pretty_print()\n",
        "          \n",
        "          if result == 1:\n",
        "            print('New model wins')\n",
        "            wins += 1\n",
        "          elif result == -1:\n",
        "            print('New model looses')\n",
        "            losses += 1\n",
        "          else:\n",
        "            print('Draw')\n",
        "            wins += 1e-4\n",
        "\n",
        "      print('Evaluation done')\n",
        "\n",
        "      return wins, losses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TDla3TWVEF-",
        "outputId": "4d108d55-c516-4fdb-f621-0453de5cb783"
      },
      "source": [
        "B = Board()\n",
        "N = NNet(B.height, B.width)\n",
        "T = Train(B, N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing model:\n",
            "conv: (None, 6, 7, 256)\n",
            "res (None, 6, 7, 256)\n",
            "pi (None, 7)\n",
            "v (None, 1)\n",
            "Initializing model:\n",
            "conv: (None, 7, 6, 256)\n",
            "res (None, 7, 6, 256)\n",
            "pi (None, 7)\n",
            "v (None, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "NfaxWHH9VEF_",
        "outputId": "41d4584f-be58-4fee-a20f-214655e76e95"
      },
      "source": [
        " T.start_training()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration : 0\n",
            "Launching self simulation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-993f4b761495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-04f8a38bed53>\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m#print('Simulation self play number :', i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Self simulations done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-04f8a38bed53>\u001b[0m in \u001b[0;36mself_play\u001b[0;34m(self, board)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mbest_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_temperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mbest_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_temperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MCTS.py\u001b[0m in \u001b[0;36mget_move\u001b[0;34m(self, board, root, temp)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0miter_board\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_curr_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1606\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    620\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m      \u001b[0mthe\u001b[0m \u001b[0mread\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \"\"\"\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o_sc-ibYd-a"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9o1FkgZLBwR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbb7SNj6IutE"
      },
      "source": [
        "Available players:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XiRW8s9H7xs",
        "outputId": "65369f85-2b2d-44e9-a071-df08b95bb179"
      },
      "source": [
        "random = RandomPlayer(\"random player\")\n",
        "basic = BasicPlayer(\"Basic player\")\n",
        "alha_beta = AlphaBetaPlayer(\"Alpha Beta Player\")\n",
        "hand_player = handPlayer()\n",
        "# You can change path to the model\n",
        "alpha_zero = AlphaZeroPlayer(\"Alpha Zero Player\", '/content/drive/MyDrive/AlphaZeroModels/backup/best_model.h5' )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing model:\n",
            "conv: (None, 6, 7, 256)\n",
            "res (None, 6, 7, 256)\n",
            "pi (None, 7)\n",
            "v (None, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWKsDZHDILQ4",
        "outputId": "770024fe-aafb-4547-9137-ce4ef21c6f34"
      },
      "source": [
        "game(alpha_zero, random)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha Zero Player played: 0\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . . . . . \n",
            "\n",
            "random player played: 6\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . . . . 0 \n",
            "\n",
            "Alpha Zero Player played: 1\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X X . . . . 0 \n",
            "\n",
            "random player played: 4\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X X . . 0 . 0 \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X X . X 0 . 0 \n",
            "\n",
            "random player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . 0 . . . \n",
            "X X . X 0 . 0 \n",
            "\n",
            "Alpha Zero Player played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . 0 . . . \n",
            "X X X X 0 . 0 \n",
            "\n",
            "Alpha Zero Player wins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YirnRfTHIzMb",
        "outputId": "2f30e5c0-cb81-4441-c785-e5be49ae6c7d"
      },
      "source": [
        "game(alpha_zero, basic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha Zero Player played: 0\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . . . . . \n",
            "\n",
            "Basic player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . 0 . . . \n",
            "\n",
            "Alpha Zero Player played: 4\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . 0 X . . \n",
            "\n",
            "Basic player played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . 0 0 X . . \n",
            "\n",
            "Alpha Zero Player played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . X . . . . \n",
            "X . 0 0 X . . \n",
            "\n",
            "Basic player played: 1\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . X . . . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Alpha Zero Player played: 4\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . X . X . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Basic player played: 5\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . X . X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Basic player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . 0 . . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . . 0 . . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Basic player played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . 0 0 . . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . . X . . . \n",
            ". . 0 0 . . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Basic player played: 2\n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . 0 X . . . \n",
            ". . 0 0 . . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . X . . . \n",
            ". . . X . . . \n",
            ". . 0 X . . . \n",
            ". . 0 0 . . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Basic player played: 4\n",
            ". . . X . . . \n",
            ". . . X . . . \n",
            ". . 0 X . . . \n",
            ". . 0 0 0 . . \n",
            ". . X X X . . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Alpha Zero Player played: 5\n",
            ". . . X . . . \n",
            ". . . X . . . \n",
            ". . 0 X . . . \n",
            ". . 0 0 0 . . \n",
            ". . X X X X . \n",
            "X 0 0 0 X 0 . \n",
            "\n",
            "Alpha Zero Player wins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCDQP1njJAIW",
        "outputId": "9dff0b1b-0bb1-4300-873a-0024be97b894"
      },
      "source": [
        "game(alpha_zero, alpha_beta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha Zero Player played: 0\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . . . . . \n",
            "\n",
            "alphaBeta1 played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . 0 . . . \n",
            "\n",
            "Alpha Zero Player played: 0\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . . . . . \n",
            "X . . 0 . . . \n",
            "\n",
            "alphaBeta1 played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . . . . . . \n",
            "X . 0 0 . . . \n",
            "\n",
            "Alpha Zero Player played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . X . . . . \n",
            "X . 0 0 . . . \n",
            "\n",
            "alphaBeta1 played: 1\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . X . . . . \n",
            "X 0 0 0 . . . \n",
            "\n",
            "Alpha Zero Player played: 4\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . X . . . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "alphaBeta1 played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            "X . X 0 . . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            "X . X 0 . . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "alphaBeta1 played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . 0 X . . . \n",
            "X . X 0 . . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . 0 X . . . \n",
            "X . X 0 . . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "alphaBeta1 played: 4\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . 0 X . . . \n",
            "X . X 0 0 . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Alpha Zero Player played: 2\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . X X . . . \n",
            ". . 0 X . . . \n",
            "X . X 0 0 . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "alphaBeta1 played: 4\n",
            ". . . . . . . \n",
            ". . . . . . . \n",
            ". . X X . . . \n",
            ". . 0 X 0 . . \n",
            "X . X 0 0 . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . X X . . . \n",
            ". . 0 X 0 . . \n",
            "X . X 0 0 . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "alphaBeta1 played: 4\n",
            ". . . . . . . \n",
            ". . . X . . . \n",
            ". . X X 0 . . \n",
            ". . 0 X 0 . . \n",
            "X . X 0 0 . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Alpha Zero Player played: 3\n",
            ". . . X . . . \n",
            ". . . X . . . \n",
            ". . X X 0 . . \n",
            ". . 0 X 0 . . \n",
            "X . X 0 0 . . \n",
            "X 0 0 0 X . . \n",
            "\n",
            "Alpha Zero Player wins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrsdJ1Y9KSLx"
      },
      "source": [
        "game(alpha_zero, hand_player)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_WH-UVNJD-w"
      },
      "source": [
        "## Testing 50 games between AlphaZero and random player"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzlSsTrtfPdC",
        "outputId": "beabf35a-15ec-42cb-e9c1-9856a4bdc3d0"
      },
      "source": [
        "zwins, looses, draws = 0, 0, 0\n",
        "num_games = 50\n",
        "for i in range(num_games):\n",
        "    result = game(alpha_zero, random_player, 0)\n",
        "    print('game:', i, 'result:', result)\n",
        "    if result == 1:\n",
        "        wins += 1\n",
        "    if result == -1:\n",
        "        looses += 1\n",
        "    else:\n",
        "        draws += 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "game: 0 result: 1\n",
            "game: 1 result: 1\n",
            "game: 2 result: 1\n",
            "game: 3 result: -1\n",
            "game: 4 result: 1\n",
            "game: 5 result: 1\n",
            "game: 6 result: 1\n",
            "game: 7 result: 1\n",
            "game: 8 result: 1\n",
            "game: 9 result: 1\n",
            "game: 10 result: 1\n",
            "game: 11 result: 1\n",
            "game: 12 result: 1\n",
            "game: 13 result: 1\n",
            "game: 14 result: 1\n",
            "game: 15 result: 1\n",
            "game: 16 result: 1\n",
            "game: 17 result: 1\n",
            "game: 18 result: 1\n",
            "game: 19 result: 1\n",
            "game: 20 result: -1\n",
            "game: 21 result: 1\n",
            "game: 22 result: -1\n",
            "game: 23 result: 1\n",
            "game: 24 result: 1\n",
            "game: 25 result: 1\n",
            "game: 26 result: 1\n",
            "game: 27 result: 1\n",
            "game: 28 result: -1\n",
            "game: 29 result: 1\n",
            "game: 30 result: 1\n",
            "game: 31 result: 1\n",
            "game: 32 result: 1\n",
            "game: 33 result: 1\n",
            "game: 34 result: 1\n",
            "game: 35 result: 1\n",
            "game: 36 result: 1\n",
            "game: 37 result: 1\n",
            "game: 38 result: -1\n",
            "game: 39 result: -1\n",
            "game: 40 result: 1\n",
            "game: 41 result: 1\n",
            "game: 42 result: 1\n",
            "game: 43 result: 1\n",
            "game: 44 result: -1\n",
            "game: 45 result: 1\n",
            "game: 46 result: 1\n",
            "game: 47 result: 1\n",
            "game: 48 result: 1\n",
            "game: 49 result: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HdDgUHfXvkg",
        "outputId": "63f5cc71-e025-4abc-efc7-3edfc57a236a"
      },
      "source": [
        "print('Wins against random:', wins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wins against random: 43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIPjjSuQkCM0",
        "outputId": "0ce95972-be7b-4396-ad65-64e9cf3858e2"
      },
      "source": [
        "print('Win ratio against random:', wins/num_games, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win ratio against random: 0.86 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO3lW5rGlwkO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}